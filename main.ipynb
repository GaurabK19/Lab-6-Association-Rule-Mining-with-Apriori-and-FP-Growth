{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe491acc",
   "metadata": {},
   "source": [
    "# Lab 6: Association Rule Mining with Apriori and FP-Growth\n",
    "**Student Name:** Gaurab Karki  \n",
    "**Course:** 2025 Fall - Advanced Big Data and Data Mining (MSCS-634-B01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5217b",
   "metadata": {},
   "source": [
    "### This notebook applies Apriori and FP-Growth to the Book-Crossing ratings dataset to discover frequent itemsets and association rules, then compares both algorithms in terms of output and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee8c6ad",
   "metadata": {},
   "source": [
    "Import and Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afb9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules\n",
    "\n",
    "import time\n",
    "\n",
    "# Plot styling\n",
    "plt.style.use(\"default\")\n",
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\")\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "TOP_N_ITEMS    = 80      # number of most frequent books to keep\n",
    "MIN_SUPPORT    = 0.003   # minimum support for both Apriori and FP-Growth\n",
    "MIN_CONFIDENCE = 0.20    # minimum confidence for association rules\n",
    "LIFT_THRESHOLD = 1.05   \n",
    "\n",
    "print(\"Parameters:\")\n",
    "print(f\"TOP_N_ITEMS    = {TOP_N_ITEMS}\")\n",
    "print(f\"MIN_SUPPORT    = {MIN_SUPPORT}\")\n",
    "print(f\"MIN_CONFIDENCE = {MIN_CONFIDENCE}\")\n",
    "print(f\"LIFT_THRESHOLD = {LIFT_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d5b0b",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ce3b2",
   "metadata": {},
   "source": [
    "Load and inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4125ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1: Load data\n",
    "ratings_path = \"BX-Book-Ratings.csv\"\n",
    "\n",
    "ratings = pd.read_csv(\n",
    "    ratings_path,\n",
    "    sep=\";\",           # Book-Crossing uses semicolon separated values\n",
    "    encoding=\"latin-1\" \n",
    ")\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45615846",
   "metadata": {},
   "source": [
    "Basic structure and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape (rows, columns):\", ratings.shape)\n",
    "print(\"\\nData types:\")\n",
    "print(ratings.dtypes)\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(ratings.isna().sum())\n",
    "\n",
    "print(\"\\nBasic descriptive statistics (truncated):\")\n",
    "ratings.describe(include=\"all\").transpose().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f3fae6",
   "metadata": {},
   "source": [
    "Cleaning and filtering \n",
    "For association rules, I am plannign to want transactions where items are \"chosen\" or \"liked\". If the rating is 0 which are treated as implicit, I will keep only the items with the postive ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731cb8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_clean = ratings[ratings[\"Book-Rating\"] > 0].copy()\n",
    "ratings_clean.rename(\n",
    "    columns={\"User-ID\": \"user_id\", \"ISBN\": \"isbn\", \"Book-Rating\": \"rating\"},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "print(\"Original rows:\", len(ratings))\n",
    "print(\"Rows after keeping explicit ratings:\", len(ratings_clean))\n",
    "\n",
    "n_users = ratings_clean[\"user_id\"].nunique()\n",
    "n_items = ratings_clean[\"isbn\"].nunique()\n",
    "print(f\"Unique users: {n_users}\")\n",
    "print(f\"Unique items (books): {n_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c785e",
   "metadata": {},
   "source": [
    "To avoid huge matrices, I am only keeping the most frequently rated books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e6c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_isbns = (\n",
    "    ratings_clean[\"isbn\"]\n",
    "    .value_counts()\n",
    "    .head(TOP_N_ITEMS)\n",
    "    .index\n",
    ")\n",
    "\n",
    "ratings_popular = ratings_clean[ratings_clean[\"isbn\"].isin(popular_isbns)].copy()\n",
    "\n",
    "print(f\"Rows after restricting to top {TOP_N_ITEMS} books:\", len(ratings_popular))\n",
    "print(\"Users in popular subset:\", ratings_popular[\"user_id\"].nunique())\n",
    "print(\"Books in popular subset:\", ratings_popular[\"isbn\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b488ba0e",
   "metadata": {},
   "source": [
    "Visualizations to explire dataset and highlight the important characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7de409",
   "metadata": {},
   "source": [
    "Most frequently rated  Top 20 popular books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = (\n",
    "    ratings_popular[\"isbn\"]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "item_counts.columns = [\"isbn\", \"count\"]\n",
    "\n",
    "print(\"Top items by rating count:\")\n",
    "display(item_counts.head())\n",
    "\n",
    "if not item_counts.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=item_counts.head(20),\n",
    "        x=\"isbn\",\n",
    "        y=\"count\"\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Top 20 Most Frequently Rated Books (Popular Subset)\")\n",
    "    plt.xlabel(\"ISBN\")\n",
    "    plt.ylabel(\"Number of Ratings\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No items available for barplot; check filtering or dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa3abd6",
   "metadata": {},
   "source": [
    "Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket = (\n",
    "    ratings_popular\n",
    "    .groupby([\"user_id\", \"isbn\"])[\"rating\"]\n",
    "    .count()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Convert counts to binary: 1 if user rated the book, 0 otherwise\n",
    "basket_binary = (basket > 0).astype(int)\n",
    "\n",
    "print(\"Basket shape (users x books):\", basket_binary.shape)\n",
    "basket_binary.head()\n",
    "\n",
    "# Item co-occurrence heatmap for top 20 books\n",
    "\n",
    "top_for_heatmap = item_counts[\"isbn\"].head(20).tolist()\n",
    "basket_sub = basket_binary[top_for_heatmap]\n",
    "\n",
    "# Co-occurrence = how often each pair of books appears together in user baskets\n",
    "coocc_matrix = basket_sub.T.dot(basket_sub)\n",
    "print(\"Co-occurrence matrix shape:\", coocc_matrix.shape)\n",
    "\n",
    "if coocc_matrix.shape[0] > 1:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(\n",
    "        coocc_matrix,\n",
    "        annot=False,\n",
    "        cmap=\"Blues\"\n",
    "    )\n",
    "    plt.title(\"Item Co-occurrence Heatmap (Top 20 Books)\")\n",
    "    plt.xlabel(\"ISBN\")\n",
    "    plt.ylabel(\"ISBN\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough items for a meaningful heatmap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dc3bb3",
   "metadata": {},
   "source": [
    "### Step 2: Frequent Itemset Mining Using Apriori "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1a0df",
   "metadata": {},
   "source": [
    "Preparing the final matrix with rows = users, columns = ISBN, and values 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59546a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = basket_binary.copy()\n",
    "print(\"Transactions shape:\", transactions.shape)\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d1979f",
   "metadata": {},
   "source": [
    "Apriori frequent itemsets with min_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "freq_itemsets_ap = apriori(\n",
    "    transactions,\n",
    "    min_support=MIN_SUPPORT,\n",
    "    use_colnames=True\n",
    ")\n",
    "apriori_time = time.time() - start_time\n",
    "\n",
    "freq_itemsets_ap[\"length\"] = freq_itemsets_ap[\"itemsets\"].apply(len)\n",
    "\n",
    "print(f\"Apriori found {len(freq_itemsets_ap)} frequent itemsets \"\n",
    "      f\"with min_support={MIN_SUPPORT:.4f} in {apriori_time:.3f} seconds.\")\n",
    "\n",
    "freq_itemsets_ap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a30eeb",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb7dd1",
   "metadata": {},
   "source": [
    "Top 15 frequent 1-item itemsets (Apriori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_1_ap = (\n",
    "    freq_itemsets_ap[freq_itemsets_ap[\"length\"] == 1]\n",
    "    .sort_values(\"support\", ascending=False)\n",
    "    .head(20)\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "if not freq_1_ap.empty:\n",
    "    freq_1_ap[\"item\"] = freq_1_ap[\"itemsets\"].apply(lambda x: list(x)[0])\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=freq_1_ap,\n",
    "        x=\"item\",\n",
    "        y=\"support\"\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Top 20 Frequent 1-Itemsets (Apriori)\")\n",
    "    plt.xlabel(\"ISBN\")\n",
    "    plt.ylabel(\"Support\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No frequent 1-itemsets found for Apriori with this support threshold.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166e83d",
   "metadata": {},
   "source": [
    "Top 2-itemsets (Apriori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aec914",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_2_ap = (\n",
    "    freq_itemsets_ap[freq_itemsets_ap[\"length\"] == 2]\n",
    "    .sort_values(\"support\", ascending=False)\n",
    "    .head(20)\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "if not freq_2_ap.empty:\n",
    "    freq_2_ap[\"items\"] = freq_2_ap[\"itemsets\"].apply(lambda x: \", \".join(sorted(list(x))))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=freq_2_ap,\n",
    "        x=\"items\",\n",
    "        y=\"support\"\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Top 20 Frequent 2-Itemsets (Apriori)\")\n",
    "    plt.xlabel(\"Book combinations (ISBN)\")\n",
    "    plt.ylabel(\"Support\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No frequent 2-itemsets found for Apriori. Consider lowering MIN_SUPPORT slightly if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed764558",
   "metadata": {},
   "source": [
    "### Step 3: Frequent Itemset Mining Using FP-Growth "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37cd380",
   "metadata": {},
   "source": [
    "FP-Growth frequent itemsets with same support threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "freq_itemsets_fp = fpgrowth(\n",
    "    transactions,\n",
    "    min_support=MIN_SUPPORT,\n",
    "    use_colnames=True\n",
    ")\n",
    "fpgrowth_time = time.time() - start_time\n",
    "\n",
    "freq_itemsets_fp[\"length\"] = freq_itemsets_fp[\"itemsets\"].apply(len)\n",
    "\n",
    "print(f\"FP-Growth found {len(freq_itemsets_fp)} frequent itemsets \"\n",
    "      f\"with min_support={MIN_SUPPORT:.4f} in {fpgrowth_time:.3f} seconds.\")\n",
    "\n",
    "freq_itemsets_fp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f103cb",
   "metadata": {},
   "source": [
    "Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0fcce8",
   "metadata": {},
   "source": [
    "Top 1-itemsets (FP-Growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf2024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_1_fp = (\n",
    "    freq_itemsets_fp[freq_itemsets_fp[\"length\"] == 1]\n",
    "    .sort_values(\"support\", ascending=False)\n",
    "    .head(20)\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "if not freq_1_fp.empty:\n",
    "    freq_1_fp[\"item\"] = freq_1_fp[\"itemsets\"].apply(lambda x: list(x)[0])\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=freq_1_fp,\n",
    "        x=\"item\",\n",
    "        y=\"support\"\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Top 20 Frequent 1-Itemsets (FP-Growth)\")\n",
    "    plt.xlabel(\"ISBN\")\n",
    "    plt.ylabel(\"Support\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No frequent 1-itemsets found for FP-Growth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea015e",
   "metadata": {},
   "source": [
    "Top 2-item itemsets (FP-Growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_2_fp = (\n",
    "    freq_itemsets_fp[freq_itemsets_fp[\"length\"] == 2]\n",
    "    .sort_values(\"support\", ascending=False)\n",
    "    .head(15)\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "freq_2_fp[\"items\"] = freq_2_fp[\"itemsets\"].apply(lambda x: \", \".join(sorted(list(x))))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(\n",
    "    data=freq_2_fp,\n",
    "    x=\"items\",\n",
    "    y=\"support\"\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Top 15 Frequent 2-Itemsets (FP-Growth)\")\n",
    "plt.xlabel(\"Book combinations (ISBN)\")\n",
    "plt.ylabel(\"Support\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d56e5",
   "metadata": {},
   "source": [
    "Comparison of itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not freq_itemsets_ap.empty:\n",
    "    length_counts_ap = (\n",
    "        freq_itemsets_ap\n",
    "        .groupby(\"length\")[\"itemsets\"]\n",
    "        .count()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"itemsets\": \"count\"})\n",
    "    )\n",
    "else:\n",
    "    length_counts_ap = pd.DataFrame({\"length\": [], \"count\": []})\n",
    "\n",
    "if not freq_itemsets_fp.empty:\n",
    "    length_counts_fp = (\n",
    "        freq_itemsets_fp\n",
    "        .groupby(\"length\")[\"itemsets\"]\n",
    "        .count()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"itemsets\": \"count\"})\n",
    "    )\n",
    "else:\n",
    "    length_counts_fp = pd.DataFrame({\"length\": [], \"count\": []})\n",
    "\n",
    "print(\"Apriori length counts:\")\n",
    "display(length_counts_ap)\n",
    "\n",
    "print(\"FP-Growth length counts:\")\n",
    "display(length_counts_fp)\n",
    "\n",
    "ap_counts = length_counts_ap.copy()\n",
    "ap_counts[\"algorithm\"] = \"Apriori\"\n",
    "\n",
    "fp_counts = length_counts_fp.copy()\n",
    "fp_counts[\"algorithm\"] = \"FP-Growth\"\n",
    "\n",
    "len_compare = pd.concat([ap_counts, fp_counts], ignore_index=True)\n",
    "len_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80be6c7a",
   "metadata": {},
   "source": [
    "Visualization – number of itemsets by length and algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158026e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(\n",
    "    data=len_compare,\n",
    "    x=\"length\",\n",
    "    y=\"count\",\n",
    "    hue=\"algorithm\"\n",
    ")\n",
    "plt.title(\"Number of Frequent Itemsets by Length and Algorithm\")\n",
    "plt.xlabel(\"Itemset Length\")\n",
    "plt.ylabel(\"Count of Frequent Itemsets\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc43461f",
   "metadata": {},
   "source": [
    "Both algorithms were run on the same transactional matrix with the same minimum support threshold. The length–count table and barplot show that Apriori and FP-Growth produce essentially the **same set of frequent itemsets**, with very similar counts for each itemset length. This is expected, because FP-Growth is an optimized way of discovering the same frequent patterns that Apriori would find, just using an FP-tree instead of repeatedly generating and scanning candidate sets.\n",
    "\n",
    "The main difference is therefore **efficiency**, not the patterns themselves. In later steps I compare their runtime directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bcb3a2",
   "metadata": {},
   "source": [
    "### Step 4: Generating and analyzing association rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65784377",
   "metadata": {},
   "source": [
    "Association rules from Apriori itemsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not freq_itemsets_ap.empty:\n",
    "    rules_ap = association_rules(\n",
    "        freq_itemsets_ap,\n",
    "        metric=\"confidence\",\n",
    "        min_threshold=MIN_CONFIDENCE\n",
    "    )\n",
    "else:\n",
    "    rules_ap = pd.DataFrame()\n",
    "\n",
    "print(\"Apriori rules – total:\", len(rules_ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838674a1",
   "metadata": {},
   "source": [
    "Association rules from FP-Growth frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbef96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not freq_itemsets_fp.empty:\n",
    "    rules_fp = association_rules(\n",
    "        freq_itemsets_fp,\n",
    "        metric=\"confidence\",\n",
    "        min_threshold=MIN_CONFIDENCE\n",
    "    )\n",
    "else:\n",
    "    rules_fp = pd.DataFrame()\n",
    "\n",
    "print(\"FP-Growth rules – total:\", len(rules_fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff2489",
   "metadata": {},
   "source": [
    "Filter strong rules by lift and add readable strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85168546",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_ap_strong = rules_ap[rules_ap[\"lift\"] >= LIFT_THRESHOLD].copy() if not rules_ap.empty else pd.DataFrame()\n",
    "rules_fp_strong = rules_fp[rules_fp[\"lift\"] >= LIFT_THRESHOLD].copy() if not rules_fp.empty else pd.DataFrame()\n",
    "\n",
    "def itemset_to_str(itemset):\n",
    "    return \", \".join(sorted(list(itemset)))\n",
    "\n",
    "for df_rules in [rules_ap, rules_fp, rules_ap_strong, rules_fp_strong]:\n",
    "    if not df_rules.empty:\n",
    "        df_rules[\"antecedent_str\"] = df_rules[\"antecedents\"].apply(itemset_to_str)\n",
    "        df_rules[\"consequent_str\"] = df_rules[\"consequents\"].apply(itemset_to_str)\n",
    "\n",
    "print(\"Apriori rules – strong (lift >= threshold):\", len(rules_ap_strong))\n",
    "print(\"FP-Growth rules – strong (lift >= threshold):\", len(rules_fp_strong))\n",
    "\n",
    "# Basic stats to understand ranges\n",
    "if not rules_ap.empty:\n",
    "    print(\"\\nApriori rules – support/confidence/lift summary:\")\n",
    "    display(rules_ap[[\"support\", \"confidence\", \"lift\"]].describe())\n",
    "\n",
    "if not rules_fp.empty:\n",
    "    print(\"\\nFP-Growth rules – support/confidence/lift summary:\")\n",
    "    display(rules_fp[[\"support\", \"confidence\", \"lift\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0167d9",
   "metadata": {},
   "source": [
    "Top 10 Apriori rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6aa728",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not rules_ap_strong.empty:\n",
    "    print(\"Top Apriori rules (strong):\")\n",
    "    display(\n",
    "        rules_ap_strong.sort_values(\"confidence\", ascending=False)[\n",
    "            [\"antecedent_str\", \"consequent_str\", \"support\", \"confidence\", \"lift\"]\n",
    "        ].head(10)\n",
    "    )\n",
    "elif not rules_ap.empty:\n",
    "    print(\"No strong Apriori rules; showing top rules without lift filter:\")\n",
    "    display(\n",
    "        rules_ap.sort_values(\"confidence\", ascending=False)[\n",
    "            [\"antecedent_str\", \"consequent_str\", \"support\", \"confidence\", \"lift\"]\n",
    "        ].head(10)\n",
    "    )\n",
    "else:\n",
    "    print(\"No Apriori rules to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbc7a08",
   "metadata": {},
   "source": [
    "Top 10 FP-Growth rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f56b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not rules_fp_strong.empty:\n",
    "    print(\"Top FP-Growth rules (strong):\")\n",
    "    display(\n",
    "        rules_fp_strong.sort_values(\"confidence\", ascending=False)[\n",
    "            [\"antecedent_str\", \"consequent_str\", \"support\", \"confidence\", \"lift\"]\n",
    "        ].head(10)\n",
    "    )\n",
    "elif not rules_fp.empty:\n",
    "    print(\"No strong FP-Growth rules; showing top rules without lift filter:\")\n",
    "    display(\n",
    "        rules_fp.sort_values(\"confidence\", ascending=False)[\n",
    "            [\"antecedent_str\", \"consequent_str\", \"support\", \"confidence\", \"lift\"]\n",
    "        ].head(10)\n",
    "    )\n",
    "else:\n",
    "    print(\"No FP-Growth rules to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c87855",
   "metadata": {},
   "source": [
    "Apriori – confidence vs lift scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9463b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not rules_ap.empty:\n",
    "    plot_df_ap = rules_ap_strong if not rules_ap_strong.empty else rules_ap\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(\n",
    "        data=plot_df_ap,\n",
    "        x=\"confidence\",\n",
    "        y=\"lift\",\n",
    "        size=\"support\",\n",
    "        alpha=0.7\n",
    "    )\n",
    "    plt.title(\"Apriori Rules – Confidence vs Lift\")\n",
    "    plt.xlabel(\"Confidence\")\n",
    "    plt.ylabel(\"Lift\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No Apriori rules available to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b3caff",
   "metadata": {},
   "source": [
    "FP-Growth – confidence vs lift scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187dac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not rules_fp.empty:\n",
    "    plot_df_fp = rules_fp_strong if not rules_fp_strong.empty else rules_fp\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(\n",
    "        data=plot_df_fp,\n",
    "        x=\"confidence\",\n",
    "        y=\"lift\",\n",
    "        size=\"support\",\n",
    "        alpha=0.7\n",
    "    )\n",
    "    plt.title(\"FP-Growth Rules – Confidence vs Lift\")\n",
    "    plt.xlabel(\"Confidence\")\n",
    "    plt.ylabel(\"Lift\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No FP-Growth rules available to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77bea7c",
   "metadata": {},
   "source": [
    "The association rules derived from both Apriori and FP-Growth capture how likely certain books are to be rated together by the same users.\n",
    "\n",
    "In general, rules with **higher support** correspond to relationships that apply to a larger portion of the user base, while rules with **higher confidence** represent more reliable “if–then” patterns (e.g., “if a user rated book A, there is a high probability that they also rated book B”). A **lift** value greater than 1 indicates that the antecedent and consequent co-occur more often than we would expect if they were independent.\n",
    "\n",
    "In this dataset, The scatter plots of confidence versus lift show that most rules have moderate confidence and lift just above 1,\n",
    "which suggests **weak but consistent affinities** rather than extremely strong dependencies. In practice, such rules could still be useful for tasks like “customers who liked this also liked…” style recommendations, especially when combined with additional business logic or content-based similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6339e4",
   "metadata": {},
   "source": [
    "# Step 5 – Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f320030a",
   "metadata": {},
   "source": [
    "Summary comparison of Apriori vs FP-Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    \"algorithm\": [\"Apriori\", \"FP-Growth\"],\n",
    "    \"num_itemsets\": [len(freq_itemsets_ap), len(freq_itemsets_fp)],\n",
    "    \"num_rules_total\": [len(rules_ap), len(rules_fp)],\n",
    "    \"num_rules_strong\": [len(rules_ap_strong), len(rules_fp_strong)],\n",
    "    \"runtime_seconds\": [apriori_time, fpgrowth_time]\n",
    "})\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154b0d89",
   "metadata": {},
   "source": [
    "Runtime comparison barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25476887",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(\n",
    "    data=summary,\n",
    "    x=\"algorithm\",\n",
    "    y=\"runtime_seconds\"\n",
    ")\n",
    "plt.title(\"Runtime Comparison: Apriori vs FP-Growth\")\n",
    "plt.xlabel(\"Algorithm\")\n",
    "plt.ylabel(\"Runtime (seconds)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597c4ca",
   "metadata": {},
   "source": [
    "**Results comparison.**  \n",
    "Using the same minimum support threshold, Apriori and FP-Growth produced verysimilar sets of frequent itemsets. The length–count comparison in Step 3 shows that the number of 1-item and 2-item patterns is almost identical across both algorithms. The strong association rules (lift > 1 generated in Step 4 are also very similar, because both algorithms are mining from essentially the same frequent itemsets.\n",
    "\n",
    "**Efficiency comparison.**  \n",
    "From the `summary` table, FP-Growth completed in less time than Apriori on this dataset (based on the `runtime_seconds` values observed during execution). This matches the theoretical expectation: Apriori repeatedly generates candidate itemsets and rescans the entire transaction matrix, while FP-Growth compresses transactions into an FP-tree and mines patterns from that structure. As a result, FP-Growth tends to scale better as the number of frequent patterns increases.\n",
    "\n",
    "**Challenges and how they were resolved.**\n",
    "\n",
    "1. **Library installation.** Initially, the notebook raised a\n",
    "   `ModuleNotFoundError: No module named 'mlxtend'`. The environment also did not recognize `pip` directly in the terminal. This was resolved by using `pip3` and installing `mlxtend` for the correct Python interprete (`pip3 install mlxtend`), after which the Apriori and FP-Growth implementations became available.\n",
    "\n",
    "2. **Choosing appropriate thresholds.** With a higher minimum support and confidence, very few 2-itemsets and almost no strong association rules were found, which led to nearly empty visualizations (especially the confidence vs lift scatter plots). I iteratively lowered the minimum support and confidence values until I obtained a reasonable number of patterns while still focusing on meaningful relationships. This tuning step is important in practice because real transactional datasets are often sparse.\n",
    "\n",
    "3. **Dealing with empty or misleading graphs.** At one point, scatter plots were rendered but had no points, making it look like the code was broken. The cause was that the rules were being filtered aggressively (e.g., by lift and confidence) before plotting. By relaxing the thresholds and, if needed, plotting all rules when the “strong” subset was empty, I ensured that the visualizations always contained interpretable information.\n",
    "\n",
    "Overall, Apriori is easier to understand conceptually, but FP-Growth offers better\n",
    "runtime behavior on this dataset. The main practical work in the lab involved\n",
    "validating the environment, selecting sensible thresholds, and making sure the\n",
    "visualizations reflected the underlying patterns rather than artifacts of overly\n",
    "strict filtering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
